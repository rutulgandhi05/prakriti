pretrained_model_name_or_path: stabilityai/stable-diffusion-xl-base-1.0
pretrained_vae_model_name_or_path: madebyollin/sdxl-vae-fp16-fix

inference_prompt: A hyper-realistic portrait of a wise, gentle elderly man with brown eyes and a well-groomed white beard. Soft sunlight illuminates his face, highlighting fine wrinkles. He wears a dark green robe with gold embroidery that falls gracefully. The softly blurred background enhances focus on his dignified expression, captured in ultra-realistic, high-quality photography with rich color tones and soft bokeh.

learnable_property: object
initializer_token: cha
placeholder_token: e<r$i>n
repeats: 1
save_as_full_pipeline: true
validation_prompt: A photo of e<r$i>n 
caption_column: text
resolution: 1024
random_flip: true
train_batch_size: 1
num_train_epochs: 1
checkpointing_steps: 500
learning_rate: 0.00003
lr_scheduler: constant
lr_warmup_steps: 0
mixed_precision: bf16
seed: 45
character_name: erin
output_dir: data/erin/experiments
train_data_dir: data/erin/loop_images
backup_data_dir_root: data/erin  # Your dataset backup folder
# lora_ckpt_dir: checkpoint-1200
max_train_steps: 500
num_of_generated_img: 127
dmin_c: 10
dsize_c: 20         
infer_steps: 35
adam_epsilon: 0.000000001
adam_weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.99
max_loop: 5
convergence_scale: 0.85  # 80% in the paper
min_samples: 5 

# Enhancements
high_learning_rate: 0.00003     # Initial high learning rate
low_learning_rate: 0.000005     # Lower learning rate after consistency threshold
consistency_threshold: 0.9     # Character consistency threshold
use_dinov2_clip: true           # Use both DINOv2 and CLIP models for embedding extraction
use_dual_tokenizers: true
character_consistency_threshold: 0.85  # Consistency level required to be considered converged
cluster_specific_finetune: true  # Enable fine-tuning for individual clusters

# inherited from origin, no need to change
gradient_accumulation_steps: 1
report_to: tensorboard
push_to_hub: false
num_vectors: 1
enable_xformers_memory_efficient_attention: false
rank: 4
train_text_encoder: false
allow_tf32: false
scale_lr: false
use_8bit_adam: false
text_inv: true  # Enable textual inversion fine-tuning
lora: true      # Enable LoRA fine-tuning
center_crop: true
dataloader_num_workers: 0
noise_offset: 0
max_grad_norm: 1.0
num_validation_images: 4
validation_epochs: 1
eps = 0.5
